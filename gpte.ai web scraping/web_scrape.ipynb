{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06aad58b",
   "metadata": {},
   "source": [
    "<h1>GPTE.AI WEB SCRAPING<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c1e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing relevant libraries\n",
    "import re\n",
    "import csv\n",
    "import requests\n",
    "from PIL import Image\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d01ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"https://gpte.ai\"\n",
    "image_file = \"images/{}.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62628f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using requests and beautifulsoup to access and get the websites comtents\n",
    "page = requests.get(target)\n",
    "soup = BeautifulSoup(page.content,'html.parser')\n",
    "tools = soup.find_all('article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0f88ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty lists to store scrape text and images\n",
    "extracted_data = []\n",
    "imgdata = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "911f67af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop that automates the scraping process and stores the scraped text and images\n",
    "for index,tool in enumerate(tools):\n",
    "    tlink = tool.find_all(\"a\")\n",
    "    tnames = tool.find_all(\"h2\")\n",
    "    tcategory = tool.find_all(\"span\",class_=\"post-card-primary-tag\")\n",
    "    tinfo = tool.find_all(\"div\",class_=\"post-card-excerpt\")\n",
    "    timages = tool.find_all(\"img\")\n",
    "    \n",
    "    for names in tnames:\n",
    "        name = names.getText().strip()\n",
    "        \n",
    "    for categories in tcategory:\n",
    "        category_1 = re.sub(r'[^a-zA-Z0-9\\._-]', '', str(categories))\n",
    "        category_2 = category_1.split('tag')\n",
    "        category = category_2[1].split('span')[0]\n",
    "        \n",
    "    for images in timages:\n",
    "        img = images[\"src\"]\n",
    "        if img[0] == '/':\n",
    "            img = target + img\n",
    "            r = requests.get(img, stream=True)\n",
    "            with open(image_file.format(name), \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "        else:\n",
    "            r = requests.get(img, stream=True)\n",
    "            with open(image_file.format(name), \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "        \n",
    "    for infos in tinfo:\n",
    "        info = infos.get_text()\n",
    "        \n",
    "        \n",
    "    for links in tlink:\n",
    "        link = target + links['href']\n",
    "        \n",
    "        \n",
    "    extracted_data.append([name, category, info, link])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d87c8292",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"Name\", \"Category\",\"Description\",\"Url\"]\n",
    "with open(\"extracted_data.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(headers)\n",
    "    writer.writerows(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af6420c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
